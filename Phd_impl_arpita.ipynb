{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2sneha4/FER24/blob/main/Phd_impl_arpita.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "student = np.dtype([('name','S20'),('age',np.int64),('marks','f4')])\n",
        "a=np.array([('akash',20,67.5),('priyam',20,89.3)],dtype=student)\n",
        "print(a['name'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncRvqklJqI7K",
        "outputId": "28f393d1-f678-4620-f076-cc5534c4db5f"
      },
      "id": "ncRvqklJqI7K",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[b'akash' b'priyam']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cbM4edtm8nTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8411724-e3fb-44b3-b77c-ea36ee1c8443"
      },
      "id": "cbM4edtm8nTx",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "liGPu9eyRfBD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing"
      ],
      "id": "liGPu9eyRfBD"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OQcZe4mYR6kf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "38751d99-2cab-4509-afc6-936ca8349b92"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/dataset (1)/adult (1).csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-54ce24a62d0a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/dataset (1)/adult (1).csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/dataset (1)/adult (1).csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/dataset (1)/adult (1).csv')\n",
        "df.head()"
      ],
      "id": "OQcZe4mYR6kf"
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "xlZRmxJMtvNq"
      },
      "id": "xlZRmxJMtvNq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jvf6FxLlR-u0"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ],
      "id": "Jvf6FxLlR-u0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nF2GwNGSBzU"
      },
      "outputs": [],
      "source": [
        "df.drop(['fnlwgt','race','capital-gain','capital-loss'],axis=1,inplace=True)\n",
        "df.replace('?',np.nan,inplace = True)\n",
        "df.dropna(inplace=True)\n",
        "df=df.drop_duplicates()\n",
        "df.shape"
      ],
      "id": "4nF2GwNGSBzU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ubiVTBXSGFa"
      },
      "outputs": [],
      "source": [
        "label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "# df['workclass'] = label_encoder.fit_transform(df['workclass'])\n",
        "# df['marital-status'] = label_encoder.fit_transform(df['marital-status'])\n",
        "# df['occupation'] = label_encoder.fit_transform(df['occupation'])\n",
        "# df['relationship'] = label_encoder.fit_transform(df['relationship'])\n",
        "df['gender'] = label_encoder.fit_transform(df['gender'])\n",
        "# df['native-country'] = label_encoder.fit_transform(df['native-country'])\n",
        "df['income'] = label_encoder.fit_transform(df['income'])\n",
        "df['age'] = label_encoder.fit_transform(df['age'])"
      ],
      "id": "2ubiVTBXSGFa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DiaM9pTSUbN"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ],
      "id": "9DiaM9pTSUbN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7MX0Sw6SWmM"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ],
      "id": "c7MX0Sw6SWmM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "353c2a5f"
      },
      "outputs": [],
      "source": [
        "plt.hist(df['age'])\n",
        "# add labels and title\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Age')"
      ],
      "id": "353c2a5f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63a47a19"
      },
      "outputs": [],
      "source": [
        "df['income'].value_counts().plot(kind='bar')"
      ],
      "id": "63a47a19"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa20013d"
      },
      "outputs": [],
      "source": [
        "plt.hist(df['workclass'])\n",
        "# add labels and title\n",
        "plt.xlabel('workclass')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of workclass')"
      ],
      "id": "aa20013d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lKqpr6I9-hL"
      },
      "outputs": [],
      "source": [
        "plt.hist(df['educational-num'])\n",
        "# add labels and title\n",
        "plt.xlabel('education')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of educational-num')"
      ],
      "id": "-lKqpr6I9-hL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUBI68im-Be7"
      },
      "outputs": [],
      "source": [
        "plt.hist(df['occupation'])\n",
        "# add labels and title\n",
        "plt.xlabel('occupation')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of occupation')"
      ],
      "id": "cUBI68im-Be7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NH7bvmtn-Dwk"
      },
      "outputs": [],
      "source": [
        "df['gender'].value_counts().plot(kind='bar')"
      ],
      "id": "NH7bvmtn-Dwk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d339757e"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "def generate_dataset(file_path, n):\n",
        "    \"\"\"\n",
        "    Create a dataset contaning n-long rows\n",
        "\n",
        "    :param file_path: The path where the CSV file will be save\n",
        "    :param n: The amount of rows to be generated randomly\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    countries = [\"Algeria\",\" Angola\",\" Benin\",\" Botswana\",\" Burkina Faso\",\\\n",
        "                     \"Burundi\",\" Cameroon\",\" Cabo Verde\",\" Central African Republic\",\\\n",
        "                     \"Chad\",\" Comoros\",\" Congo\",\" Congo\",\\\n",
        "                     \"Cote d’Ivoire\",\" Djibouti\",\" Equatorial Guinea\",\" Egypt\",\" Eritrea\",\\\n",
        "                     \"Ethiopia\",\" Gabon\",\" Gambia\",\" Ghana\",\" Guinea\",\"Kenya\",\"Lesotho\",\"Liberia\",\\\n",
        "                     \"Libya\",\" Madagascar\",\" Malawi\",\" Mali\",\" Mauritania\",\" Mauritius\",\" Morocco\",\\\n",
        "                     \"Mozambique\",\" Namibia\",\" Niger\",\" Nigeria\",\" Rwanda\",\" Sao Tome and Principe\",\\\n",
        "                     \"Senegal\",\" Seychelles\",\" Sierra Leone\",\" Somalia\",\" South Africa\",\" South Sudan\",\\\n",
        "                     \"Sudan\",\" Tanzania\",\" Togo\",\" Tunisia\",\" Uganda\",\"Zimbabwe.\"]\n",
        "    conditions = [\"heart\",\"viral\",\"cancer\",\"bacteria\",\"kidney\",\"diabetes\"]\n",
        "    gender = [\"male\",\"female\"]\n",
        "\n",
        "    # Initiate random generation\n",
        "    with open(file_path, \"w\") as f:\n",
        "        # print headers\n",
        "        f.write(\"country,condition,age,gender\\n\")\n",
        "        for i in range(n):\n",
        "            country = countries[random.randint(0, len(countries)-1)]\n",
        "            condition = conditions[random.randint(0, len(conditions)-1)]\n",
        "            age = random.randint(5,110)\n",
        "            gend = gender[random.randint(0,1)]\n",
        "\n",
        "            f.write(\"{},{},{},{}\\n\".format(country, condition, age, gend))\n"
      ],
      "id": "d339757e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aebfd87"
      },
      "outputs": [],
      "source": [
        "from os import XATTR_REPLACE\n",
        "def k_anonymize(dataset, columns):\n",
        "\n",
        "    anon_dataset = dataset.copy()\n",
        "\n",
        "    # Target all sensitive columns\n",
        "    for column in columns:\n",
        "        column_label = column['label']\n",
        "        if column['type'] == 'suppressed':\n",
        "            # Replace all characters with asterix\n",
        "            anon_dataset[column_label] = ['*' for x in anon_dataset[column_label]]\n",
        "\n",
        "        if column['type'] == 'semi-suppressed':\n",
        "            # Replace 70% of the characters with asterix\n",
        "            anon_dataset[column_label] = [('*'*(round(len(x)*.7)) + x[(round(len(x)*.7)):]) for x in anon_dataset[column_label]]\n",
        "\n",
        "        if column['type'] == 'generalized':\n",
        "            # Summarize the data using ranges\n",
        "            for i in range(len(anon_dataset[column_label])):\n",
        "                print (\"i ==============\",i,'label ===>',anon_dataset[column_label])\n",
        "                # convert column type from int to string\n",
        "                anon_dataset[column_label] = anon_dataset[column_label].astype(str)\n",
        "                # print(anon_dataset[column_label])\n",
        "                # x = int(anon_dataset[column_label][i])\n",
        "                # print (\"value of x ---------------\",x)\n",
        "                # if x <= 40:\n",
        "                #   anon_dataset[column_label][i] =  \"0-40\"\n",
        "                # if x > 40 and x <= 60:\n",
        "                #   anon_dataset[column_label][i] =  \"40-60\"\n",
        "                # if x > 60 and x <= 100:\n",
        "                #   anon_dataset[column_label][i] =  \"> 60\"\n",
        "\n",
        "    return anon_dataset\n",
        "\n",
        "# Describe the columns and their respective anonymization type\n",
        "columns = [\n",
        "    {\"label\": \"education\", \"type\": \"semi-suppressed\"},\n",
        "    {\"label\": \"relationship\", \"type\": \"suppressed\"},\n",
        "    {\"label\": \"native-country\", \"type\": \"semi-suppressed\"},\n",
        "    {\"label\": \"income\", \"type\": \"generalized\"},\n",
        "    {\"label\": \"age\", \"type\": \"generalized\"}\n",
        "\n",
        "]\n",
        "\n",
        "dataset = df\n",
        "anonymized_dataset = k_anonymize(dataset, columns)"
      ],
      "id": "7aebfd87"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c27af2c7"
      },
      "outputs": [],
      "source": [
        "df.head(1000)"
      ],
      "id": "c27af2c7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0071eab"
      },
      "outputs": [],
      "source": [
        "anonymized_dataset.head(1000)"
      ],
      "id": "f0071eab"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f26a79a1"
      },
      "outputs": [],
      "source": [
        "!pip install diffprivlib"
      ],
      "id": "f26a79a1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43f1b0c5"
      },
      "outputs": [],
      "source": [
        "from diffprivlib.mechanisms import LaplaceTruncated\n",
        "\n",
        "sensitivity=3\n",
        "epsilon=0.3\n",
        "mechanism = LaplaceTruncated(sensitivity=sensitivity, epsilon=epsilon, lower=5, upper=100)\n",
        "laplace_dataset = df.copy()\n",
        "laplace_dataset['income'] = [mechanism.randomise(laplace_dataset['income'][x]) for x in laplace_dataset['income']]\n",
        "\n",
        "laplace_dataset.head(1000)\n"
      ],
      "id": "43f1b0c5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1e4d8f4"
      },
      "outputs": [],
      "source": [
        "from diffprivlib.mechanisms import Exponential\n",
        "\n",
        "exp_dataset = df.copy()\n",
        "sensitivity = 3\n",
        "epsilon = 0.3\n",
        "utility = [random.randint(0,1) for x in range(len(exp_dataset['gender']))]\n",
        "candidates = exp_dataset['gender'].values.tolist()\n",
        "\n",
        "mechanism = Exponential(\n",
        "    sensitivity=sensitivity,\n",
        "    epsilon=epsilon,\n",
        "    utility=utility,\n",
        "    candidates=candidates\n",
        ")\n",
        "\n",
        "exp_dataset['gender'] = [mechanism.randomise() for _ in range(len(exp_dataset['gender']))]\n",
        "exp_dataset.head(1000)\n"
      ],
      "id": "c1e4d8f4"
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import random\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('reuters')\n",
        "from nltk.corpus import reuters\n",
        "from nltk import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from collections import defaultdict, Counter\n",
        "import collections\n",
        "# input the reuters sentences\n",
        "sents  =reuters.sents()\n",
        "\n",
        "# write the removal characters such as : Stopwords and punctuation\n",
        "stop_words = set(stopwords.words('english'))\n",
        "string.punctuation = string.punctuation +'\"'+'\"'+'-'+'''+'''+'—'\n",
        "string.punctuation\n",
        "removal_list = list(stop_words) + list(string.punctuation)+ ['lt','rt']\n",
        "removal_list\n",
        "\n",
        "# generate unigrams bigrams trigrams\n",
        "unigram=[]\n",
        "bigram=[]\n",
        "trigram=[]\n",
        "tokenized_text=[]\n",
        "for sentence in sents:\n",
        "  sentence = list(map(lambda x:x.lower(),sentence))\n",
        "  for word in sentence:\n",
        "        if word== '.':\n",
        "            sentence.remove(word)\n",
        "        else:\n",
        "            unigram.append(word)\n",
        "\n",
        "  tokenized_text.append(sentence)\n",
        "  bigram.extend(list(ngrams(sentence, 2,pad_left=True, pad_right=True)))\n",
        "  trigram.extend(list(ngrams(sentence, 3, pad_left=True, pad_right=True)))\n",
        "\n",
        "# remove the n-grams with removable words\n",
        "def remove_stopwords(x):\n",
        "    y = []\n",
        "    for pair in x:\n",
        "        count = 0\n",
        "        for word in pair:\n",
        "            if word in removal_list:\n",
        "                count = count or 0\n",
        "            else:\n",
        "                count = count or 1\n",
        "        if (count==1):\n",
        "            y.append(pair)\n",
        "    return"
      ],
      "metadata": {
        "id": "MnWpyvoGI-Sw"
      },
      "id": "MnWpyvoGI-Sw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea72e859"
      },
      "outputs": [],
      "source": [
        "final_dataset = pd.concat([\n",
        "                            df,\n",
        "                            pd.DataFrame(exp_dataset['gender']).add_prefix('anon_'),\n",
        "                            pd.DataFrame(laplace_dataset['age']).add_prefix('anon_'),\n",
        "                          ],\n",
        "                          axis=1)\n",
        "final_dataset.head(1000)"
      ],
      "id": "ea72e859"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gT1iGNmNEcao"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n"
      ],
      "id": "gT1iGNmNEcao"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndGVLqfyMHzT"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "y = final_dataset['income']\n",
        "df_train, df_test, DF_train, DF_test = train_test_split(final_dataset, y,test_size=0.20, random_state=42)"
      ],
      "id": "ndGVLqfyMHzT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DR8U3pyTEcap"
      },
      "outputs": [],
      "source": [
        "catagorial_df_train=df_train.select_dtypes(\"object\")\n",
        "catagorial_df_train.head()"
      ],
      "id": "DR8U3pyTEcap"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P6jjJiuEcap"
      },
      "outputs": [],
      "source": [
        "# apply Label encoder to df_categorical\n",
        "le=preprocessing.LabelEncoder()"
      ],
      "id": "4P6jjJiuEcap"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkCvxpI6Ecap"
      },
      "outputs": [],
      "source": [
        "catagorial_df_train=catagorial_df_train.apply(le.fit_transform)"
      ],
      "id": "PkCvxpI6Ecap"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vK0m4bHyEcap"
      },
      "outputs": [],
      "source": [
        "catagorial_df_train.head()"
      ],
      "id": "vK0m4bHyEcap"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqkH1jvoEcap"
      },
      "outputs": [],
      "source": [
        "#concat catagorial_df_train to df_train\n",
        "train=df_train.drop(catagorial_df_train.columns,axis=1)\n",
        "train=pd.concat([train,catagorial_df_train],axis=1)"
      ],
      "id": "TqkH1jvoEcap"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yALwgf8aEcap"
      },
      "outputs": [],
      "source": [
        "catagorial_df_test=df_test.select_dtypes(\"object\")\n",
        "catagorial_df_test=catagorial_df_test.apply(le.fit_transform)\n",
        "test=df_test.drop(catagorial_df_train.columns,axis=1)\n",
        "test=pd.concat([test,catagorial_df_test],axis=1)\n",
        "test.head()"
      ],
      "id": "yALwgf8aEcap"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJt-OprCEcaq"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ],
      "id": "PJt-OprCEcaq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSAkkUAQEcaq"
      },
      "outputs": [],
      "source": [
        "train.dtypes"
      ],
      "id": "iSAkkUAQEcaq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfrkqK2BEcaq"
      },
      "outputs": [],
      "source": [
        "train[\"income\"]=train[\"income\"].astype(\"int64\")\n",
        "train[\"income\"].value_counts()"
      ],
      "id": "JfrkqK2BEcaq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCVNALRFEcaq"
      },
      "source": [
        "Get X_trainD,Y_trainD,X_testD,Y_testD"
      ],
      "id": "bCVNALRFEcaq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQNgWVpbEcaq"
      },
      "outputs": [],
      "source": [
        "X_trainD=train.drop(\"income\",axis=1)\n",
        "Y_trainD=train[\"income\"]\n",
        "\n",
        "X_testD=test.drop(\"income\",axis=1)\n",
        "Y_testD=test[\"income\"]"
      ],
      "id": "DQNgWVpbEcaq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEuMMUhyEcaq"
      },
      "outputs": [],
      "source": [
        "print(X_trainD.shape)\n",
        "print(Y_trainD.shape)\n",
        "print(X_testD.shape)\n",
        "print(Y_testD.shape)"
      ],
      "id": "UEuMMUhyEcaq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJUNCuG7Ecar",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "X_trainD.occupation.dtype"
      ],
      "id": "WJUNCuG7Ecar"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UaetLomEcar"
      },
      "outputs": [],
      "source": [
        "Y_trainD.head()"
      ],
      "id": "3UaetLomEcar"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuoThQz0Ecar"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "id": "JuoThQz0Ecar"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3w4OeerEcar"
      },
      "outputs": [],
      "source": [
        "accuracy_list_train=[]\n",
        "accuracy_list_test=[]\n",
        "for i in range(1,30):\n",
        "    dt_default = DecisionTreeClassifier(criterion='gini',max_depth=i)\n",
        "    dt_default.fit(X_trainD, Y_trainD)\n",
        "    Y_trainD_pred=dt_default.predict(X_trainD)\n",
        "    Y_testD_pred=dt_default.predict(X_testD)\n",
        "    accuracy_list_train.append(accuracy_score(Y_trainD_pred,Y_trainD))\n",
        "    accuracy_list_test.append(accuracy_score(Y_testD_pred,Y_testD))\n",
        "plt.plot(accuracy_list_train)\n",
        "plt.title(\"train\")\n",
        "plt.plot(accuracy_list_test)\n",
        "plt.show()"
      ],
      "id": "D3w4OeerEcar"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBXYCixzEcar"
      },
      "source": [
        "We can see there max depth around 4 is giving good performance"
      ],
      "id": "tBXYCixzEcar"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnoCe2EOEcar"
      },
      "outputs": [],
      "source": [
        "dt_default = DecisionTreeClassifier(max_depth=4)\n",
        "dt_default.fit(X_trainD, Y_trainD)"
      ],
      "id": "hnoCe2EOEcar"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjP6ib-nEcas"
      },
      "outputs": [],
      "source": [
        "Y_trainD_pred=dt_default.predict(X_trainD)\n",
        "Y_testD_pred=dt_default.predict(X_testD)"
      ],
      "id": "GjP6ib-nEcas"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhvOa6K4Ecas"
      },
      "outputs": [],
      "source": [
        "accuracy_score(Y_trainD_pred,Y_trainD)"
      ],
      "id": "DhvOa6K4Ecas"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3K8yANJEcas"
      },
      "outputs": [],
      "source": [
        "confusion_matrix(Y_trainD_pred,Y_trainD)"
      ],
      "id": "y3K8yANJEcas"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAHKtJVZEcas"
      },
      "outputs": [],
      "source": [
        "accuracy_score(Y_testD_pred,Y_testD)"
      ],
      "id": "LAHKtJVZEcas"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UnRTzqSEcas"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "confusion_matrix(Y_testD_pred,Y_testD)"
      ],
      "id": "3UnRTzqSEcas"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU_FrR3uEcas"
      },
      "source": [
        "#### RandomForestClassifier"
      ],
      "id": "RU_FrR3uEcas"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYxwNK2eEcas"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=10,criterion='entropy',max_depth=5)  # n_estimators : no. of tree"
      ],
      "id": "cYxwNK2eEcas"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Li75IGMwEcat"
      },
      "outputs": [],
      "source": [
        "rf.fit(X_trainD, Y_trainD)"
      ],
      "id": "Li75IGMwEcat"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-YbrknUEcat"
      },
      "outputs": [],
      "source": [
        "Y_trainD_pred=rf.predict(X_trainD)\n",
        "Y_testD_pred=rf.predict(X_testD)\n",
        "print(accuracy_score(Y_trainD_pred,Y_trainD))\n",
        "print(accuracy_score(Y_testD_pred,Y_testD))"
      ],
      "id": "A-YbrknUEcat"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpV45UHaEcat"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "acc=cross_val_score(RandomForestClassifier(n_estimators=10,criterion='entropy',max_depth=5),X_trainD,Y_trainD,cv=5).mean()"
      ],
      "id": "GpV45UHaEcat"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q19273U5Ecat"
      },
      "outputs": [],
      "source": [
        "print(acc)"
      ],
      "id": "Q19273U5Ecat"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gyo585z7Ecat"
      },
      "source": [
        "This is solved by cross validation with RandomForest"
      ],
      "id": "Gyo585z7Ecat"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55hbn3xREcat"
      },
      "outputs": [],
      "source": [
        "acc_list=[]\n",
        "for i in range(1,50):\n",
        "    acc = cross_val_score(RandomForestClassifier(n_estimators=i,max_depth=5),X_trainD,Y_trainD,cv=5).mean()\n",
        "    acc_list.append(acc)"
      ],
      "id": "55hbn3xREcat"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsRTzC1kEcat"
      },
      "outputs": [],
      "source": [
        "plt.plot(acc_list)\n",
        "plt.show()"
      ],
      "id": "nsRTzC1kEcat"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9cbCFBmEcau"
      },
      "outputs": [],
      "source": [
        "print(np.argmax(acc_list))"
      ],
      "id": "T9cbCFBmEcau"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_T9sSCaEcau"
      },
      "source": [
        "Means 30 tree gives best result"
      ],
      "id": "Z_T9sSCaEcau"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J64_SLoREcau"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(n_estimators=30,max_depth=5,criterion='entropy')\n",
        "rf.fit(X_trainD,Y_trainD)\n",
        "print(rf.score(X_trainD,Y_trainD))\n",
        "print(rf.score(X_testD,Y_testD))"
      ],
      "id": "J64_SLoREcau"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VZQgoetEcau"
      },
      "source": [
        "Now we do another algo for solve classification problem : Logistic Regrassion"
      ],
      "id": "_VZQgoetEcau"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jfa2ALkYEcau"
      },
      "source": [
        "### encoding by dummies"
      ],
      "id": "Jfa2ALkYEcau"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuYHHQcTFXTW"
      },
      "outputs": [],
      "source": [
        "train[\"income\"].value_counts()\n",
        "train"
      ],
      "id": "ZuYHHQcTFXTW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cw5qZs8IEcau"
      },
      "outputs": [],
      "source": [
        "#train[\"income\"]=df_train[\"income\"].apply(lambda x: 0 if x ==\"0\" else 1)"
      ],
      "id": "cw5qZs8IEcau"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qc26Se88Ecau"
      },
      "outputs": [],
      "source": [
        "#train[\"income\"]=df_train[\"income\"].astype(\"object\")\n",
        "#train[\"income\"].value_counts()"
      ],
      "id": "qc26Se88Ecau"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpH-JmPREcav"
      },
      "outputs": [],
      "source": [
        "# test[\"income\"]=df_test[\"income\"].apply(lambda x: 0 if x ==\">50K\" else 1)\n",
        "#df_test[\"incomet\"]=df_test[\"income\"].astype(\"object\")\n",
        "test['income'].value_counts()"
      ],
      "id": "FpH-JmPREcav"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I798yJ3cEcav"
      },
      "outputs": [],
      "source": [
        "catagorial_train=train.select_dtypes(\"object\")\n",
        "#catagorial_train.drop(\"income\",axis=1,inplace=True)"
      ],
      "id": "I798yJ3cEcav"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKKcEJUxEcav"
      },
      "outputs": [],
      "source": [
        "#train\n",
        "train_dummies=train.drop(catagorial_train.columns,axis=1)\n",
        "#train_dummies=pd.concat([train,pd.get_dummies(catagorial_df_train)],axis=1)\n",
        "train_dummies.head()"
      ],
      "id": "FKKcEJUxEcav"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkLCyjNXEcav"
      },
      "outputs": [],
      "source": [
        "train_dummies.income_bracket=train[\"income\"].astype(\"uint8\")"
      ],
      "id": "tkLCyjNXEcav"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OX7q4uQbEcav",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#test\n",
        "catagorial_df_test=test.select_dtypes(\"object\")\n",
        "#catagorial_df_test.drop(\"income\",axis=1,inplace=True)\n",
        "test_dummies=test.drop(catagorial_df_test.columns,axis=1)\n",
        "#test_dummies=pd.concat([test_dummies,pd.get_dummies(catagorial_df_test)],axis=1)\n",
        "test_dummies.head()"
      ],
      "id": "OX7q4uQbEcav"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2rTP-IWEcav"
      },
      "outputs": [],
      "source": [
        "test_dummies.income_bracket=test_dummies[\"income\"].astype(\"uint8\")"
      ],
      "id": "L2rTP-IWEcav"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuZQEg6pEcav"
      },
      "source": [
        "## Model Building and Evaluation"
      ],
      "id": "BuZQEg6pEcav"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE0h_dNIEcaw"
      },
      "source": [
        "Get X_train, Y_train"
      ],
      "id": "cE0h_dNIEcaw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qOksQSYEcaw"
      },
      "source": [
        "Logistic"
      ],
      "id": "4qOksQSYEcaw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDjCssMZEcaw"
      },
      "outputs": [],
      "source": [
        "X_train=train_dummies.drop(\"income\",axis=1)\n",
        "\n",
        "Y_train=train_dummies[\"income\"].astype(int)\n",
        "\n",
        "X_test=test_dummies.drop(\"income\",axis=1)\n",
        "Y_test=test_dummies[\"income\"].astype(int)\n"
      ],
      "id": "ZDjCssMZEcaw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nN8pajzEYNmO"
      },
      "outputs": [],
      "source": [
        "X_train"
      ],
      "id": "nN8pajzEYNmO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qOXHW1DYScz"
      },
      "outputs": [],
      "source": [
        "Y_train\n",
        "Y_train.value_counts()"
      ],
      "id": "6qOXHW1DYScz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfVXTT1qEcaw"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "id": "kfVXTT1qEcaw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIcCo958Ecax"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "id": "VIcCo958Ecax"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHpXbUYOEcax"
      },
      "outputs": [],
      "source": [
        "logistic_model=LogisticRegression()\n",
        "logistic_model.fit(X_train,Y_train)"
      ],
      "id": "FHpXbUYOEcax"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxNkiq1tEcay"
      },
      "outputs": [],
      "source": [
        "Y_test_pred=logistic_model.predict(X_test)"
      ],
      "id": "fxNkiq1tEcay"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O2lmWWMEcay"
      },
      "outputs": [],
      "source": [
        "accuracy_score(Y_test_pred,Y_test)"
      ],
      "id": "2O2lmWWMEcay"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IGMU-XUEcaz"
      },
      "outputs": [],
      "source": [
        "Y_train_pred=logistic_model.predict(X_train)\n",
        "accuracy_score(Y_train,Y_train_pred)"
      ],
      "id": "-IGMU-XUEcaz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeVi3f9VID2h"
      },
      "outputs": [],
      "source": [
        "x = np.arange(len(Y_test_pred)) + 1 # Create domain for plot\n",
        "train_errors = [error for error in errors if error[0] == 'train']\n",
        "test_errors = [error for error in errors if error[0] == 'test']\n",
        "plt.plot(x, train_errors, label='Training Error') # Plot training error over domain\n",
        "plt.plot(x, test_errors, label='Testing Error') # Plot testing error over domain\n",
        "plt.xlabel('Maximum Depth') # Label x-axis\n",
        "plt.ylabel('Total Error') # Label y-axis\n",
        "plt.legend() # Show plot labels as legend\n",
        "plt.show() # Show graph"
      ],
      "id": "LeVi3f9VID2h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjPtRFISvsLf"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "res = mean_squared_error(Y_test,Y_pred)\n",
        "print(res)\n",
        "# Where:\n",
        "# n is the number of samples in the test set.\n",
        "# Σ denotes the sum over all samples.\n",
        "# \"actual\" represents the actual target values.\n",
        "# \"predicted\" represents the predicted values\n"
      ],
      "id": "OjPtRFISvsLf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86ZE-SEzv7wY"
      },
      "outputs": [],
      "source": [
        "MSE = np.square(np.subtract(Y_test,Y_pred)).mean()\n",
        "print(MSE)"
      ],
      "id": "86ZE-SEzv7wY"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pkLIZLavQors"
      },
      "id": "pkLIZLavQors"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5YTfbEbv5-L"
      },
      "outputs": [],
      "source": [
        "sum_original_dataset = BoundedSum(epsilon= 1.5, lower_bound =  5, upper_bound = 250, dtype ='float')\n",
        "dp_sum_og = df.quick_result(original_dataset['income'].to_list())\n",
        "dp_sum_og = round(dp_sum_og, 2)\n",
        "print(dp_sum_og)"
      ],
      "id": "h5YTfbEbv5-L"
    },
    {
      "cell_type": "code",
      "source": [
        "sum_original_dataset = round(sum(original_dataset['income'].to_list()), 2)\n",
        "sum_redact_dataset = round(sum(redact_dataset['income'].to_list()), 2)\n",
        "sales_amount_Osbourne = round((sum_original_dataset - sum_redact_dataset), 2)\n",
        "assert sales_amount_Osbourne == original_dataset.iloc[0, 4]"
      ],
      "metadata": {
        "id": "niR4mWT-SjPi"
      },
      "id": "niR4mWT-SjPi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dp_redact_dataset = BoundedSum(epsilon= 1.5, lower_bound =  5, upper_bound = 250, dtype ='float')\n",
        "dp_redact_dataset.add_entries(redact_dataset['income'].to_list())\n",
        "dp_sum_redact=round(dp_redact_dataset.result(), 2)\n",
        "print(dp_sum_redact)"
      ],
      "metadata": {
        "id": "EBED-ZqDR_oH"
      },
      "id": "EBED-ZqDR_oH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sum of sales_value in the orignal dataset: {sum_original_dataset}\")\n",
        "print(f\"Sum of sales_value in the orignal dataset with DP: {dp_sum_og}\")\n",
        "assert dp_sum_og != sum_original_dataset\n",
        "\n",
        "\n",
        "print(f\"Sum of sales_value in the second dataset: {dp_redact_dataset}\")\n",
        "print(f\"Sum of sales_value in the second dataset with DP: {dp_sum_redact}\")\n",
        "assert dp_sum_redact != dp_sum_redact\n",
        "\n",
        "print(f\"Difference in Sum with DP: {round(dp_sum_og - dp_sum_redact, 2)}\")\n",
        "print(f\"Actual Difference in Sum: {sales_amount_Osbourne}\")\n",
        "assert round(dp_sum_og - dp_sum_redact, 2) != sales_amount_Osbourne"
      ],
      "metadata": {
        "id": "sthq_pLYSE2k"
      },
      "id": "sthq_pLYSE2k",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 90.448013,
      "end_time": "2022-01-10T22:59:16.284261",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-01-10T22:57:45.836248",
      "version": "2.3.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}